{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102b3dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4caa84d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92408be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "947963d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_interact = ChatOpenAI(model = \"gpt-4.1-nano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0d22c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Asked Question: What is LangChain\n",
      "LLM Answered: LangChain is an open-source framework designed to facilitate the development of applications that utilize large language models (LLMs). It provides tools, abstractions, and pre-built components to help developers build, deploy, and manage sophisticated AI-powered systems such as chatbots, question-answering systems, and automation pipelines.\n",
      "\n",
      "Key features of LangChain include:\n",
      "\n",
      "1. **Prompt Management:** Tools to craft, manage, and optimize prompts for different LLMs.\n",
      "2. **Chains:** Modular sequences of logic that combine multiple steps, such as data retrieval, processing, and response generation.\n",
      "3. **Memory:** Components to maintain conversational context over multiple interactions.\n",
      "4. **Agents:** Frameworks that enable LLMs to decide and perform actions based on inputs and external tools or APIs.\n",
      "5. **Integration:** Support for connecting with various data sources, APIs, and vector stores to enable rich, context-aware AI applications.\n",
      "\n",
      "Overall, LangChain aims to simplify the process of building AI systems by providing reusable components and best practices, making it easier for developers to create intelligent applications that leverage the power of large language models.\n"
     ]
    }
   ],
   "source": [
    "user_question = input(\"Please ask a question to the LLM: \") # to run interactively\n",
    "result = llm_interact.invoke(user_question)\n",
    "print(f\"User Asked Question: {user_question}\")\n",
    "print(f\"LLM Answered: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5a8782c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Asked Question: What is LangGraph\n",
      "LLM Answered: LangGraph is a language modeling system that combines natural language processing with graph-based representations to improve understanding and reasoning over complex language data. It leverages graph structures to model relationships between entities, concepts, and events within text, allowing for more nuanced analysis and inference. This approach enhances tasks such as question answering, knowledge extraction, and semantic understanding by capturing the interconnected nature of language information.\n",
      "\n",
      "Would you like more detailed information about its architecture, applications, or how it integrates with other technologies?\n"
     ]
    }
   ],
   "source": [
    "user_question = \"What is LangGraph\" # to non-interactive testing\n",
    "result = llm_interact.invoke(user_question)\n",
    "print(f\"User Asked Question: {user_question}\")\n",
    "print(f\"LLM Answered: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde7b8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
